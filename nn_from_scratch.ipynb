{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import Union, Tuple, Callable, Set, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\"\n",
    "    Class to represent a value in a computational graph, supporting operations like addition,\n",
    "    multiplication, exponentiation, division, negation, and the hyperbolic tangent function.\n",
    "    It also supports automatic differentiation via the backward method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: float, _children: Tuple['Value', ...] = (), _op: str = '', label: str = ''):\n",
    "        \"\"\"\n",
    "        Initialize a Value object.\n",
    "\n",
    "        :param data: The numerical data associated with this value.\n",
    "        :param _children: The parent nodes contributing to this value in the computational graph.\n",
    "        :param _op: The operation that produced this value.\n",
    "        :param label: An optional label for this value.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._backward: Callable[[], None] = lambda: None\n",
    "        self._prev: Set['Value'] = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a string representation of the Value object.\n",
    "\n",
    "        :return: A string representation of the Value object.\n",
    "        \"\"\"\n",
    "        return f\"Value(data={self.data})\"\n",
    "\n",
    "\n",
    "    def __add__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Add another value or float to this value.\n",
    "\n",
    "        :param other: Another value or a float to add.\n",
    "        :return: The result of the addition as a new Value object.\n",
    "        \"\"\"\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def __radd__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Add another value or float to this value (reverse addition).\n",
    "\n",
    "        :param other: Another value or a float to add.\n",
    "        :return: The result of the addition as a new Value object.\n",
    "        \"\"\"\n",
    "        return self + other\n",
    "\n",
    "\n",
    "    def __mul__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Multiply this value by another value or float.\n",
    "\n",
    "        :param other: Another value or a float to multiply by.\n",
    "        :return: The result of the multiplication as a new Value object.\n",
    "        \"\"\"\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __rmul__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Multiply this value by another value or float (reverse multiplication).\n",
    "\n",
    "        :param other: Another value or a float to multiply by.\n",
    "        :return: The result of the multiplication as a new Value object.\n",
    "        \"\"\"\n",
    "        return self * other\n",
    "\n",
    "\n",
    "    def __pow__(self, other: Union[int, float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Raise this value to the power of another value or float.\n",
    "\n",
    "        :param other: The exponent, which must be an int or float.\n",
    "        :return: The result of the exponentiation as a new Value object.\n",
    "        \"\"\"\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data ** other, (self,), f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __truediv__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Divide this value by another value or float.\n",
    "\n",
    "        :param other: Another value or a float to divide by.\n",
    "        :return: The result of the division as a new Value object.\n",
    "        \"\"\"\n",
    "        return self * other**-1\n",
    "\n",
    "\n",
    "    def __neg__(self) -> 'Value':\n",
    "        \"\"\"\n",
    "        Negate this value.\n",
    "\n",
    "        :return: The negated value as a new Value object.\n",
    "        \"\"\"\n",
    "        return self * -1\n",
    "\n",
    "\n",
    "    def __sub__(self, other: Union['Value', float]) -> 'Value':\n",
    "        \"\"\"\n",
    "        Subtract another value or float from this value.\n",
    "\n",
    "        :param other: Another value or a float to subtract.\n",
    "        :return: The result of the subtraction as a new Value object.\n",
    "        \"\"\"\n",
    "        return self + (-other)\n",
    "\n",
    "\n",
    "    def tanh(self) -> 'Value':\n",
    "        \"\"\"\n",
    "        Compute the hyperbolic tangent of this value.\n",
    "\n",
    "        :return: The result of the tanh function as a new Value object.\n",
    "        \"\"\"\n",
    "        x = self.data\n",
    "        t = (math.exp(2 * x) - 1) / (math.exp(2 * x) + 1)\n",
    "        out = Value(t, (self,), 'tanh')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - t ** 2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    def exp(self) -> 'Value':\n",
    "        \"\"\"\n",
    "        Compute the exponential of this value.\n",
    "\n",
    "        :return: The result of the exp function as a new Value object.\n",
    "        \"\"\"\n",
    "        x = self.data\n",
    "        out = Value(math.exp(x), (self,), 'exp')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        \"\"\"\n",
    "        Perform backpropagation to compute the gradients of this value with respect to all\n",
    "        preceding values in the computational graph.\n",
    "        \"\"\"\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v: 'Value') -> None:\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Neuron:\n",
    "    \"\"\"\n",
    "    A single neuron in a neural network, with a set of weights and a bias.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nin: int):\n",
    "        \"\"\"\n",
    "        Initialize a Neuron with random weights and a bias.\n",
    "\n",
    "        :param nin: Number of input connections to the neuron.\n",
    "        \"\"\"\n",
    "        self.w: List[Value] = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n",
    "        self.b: Value = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x: List[Value]) -> Value:\n",
    "        \"\"\"\n",
    "        Compute the output of the neuron given an input.\n",
    "\n",
    "        :param x: List of input values.\n",
    "        :return: The output value after applying the tanh activation function.\n",
    "        \"\"\"\n",
    "        # Weighted sum of inputs plus bias\n",
    "        act = sum((wi * xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "\n",
    "    def parameters(self) -> List[Value]:\n",
    "        \"\"\"\n",
    "        Get all parameters of the neuron (weights and bias).\n",
    "\n",
    "        :return: A list containing the weights and bias.\n",
    "        \"\"\"\n",
    "        return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    A layer in a neural network, consisting of multiple neurons.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nin: int, nout: int):\n",
    "        \"\"\"\n",
    "        Initialize a Layer with a specified number of input and output connections.\n",
    "\n",
    "        :param nin: Number of input connections to each neuron.\n",
    "        :param nout: Number of neurons in this layer.\n",
    "        \"\"\"\n",
    "        self.neurons: List[Neuron] = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x: List[Value]) -> Union[Value, List[Value]]:\n",
    "        \"\"\"\n",
    "        Compute the output of the layer given an input.\n",
    "\n",
    "        :param x: List of input values.\n",
    "        :return: The output values from the layer.\n",
    "        \"\"\"\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "\n",
    "    def parameters(self) -> List[Value]:\n",
    "        \"\"\"\n",
    "        Get all parameters of the layer.\n",
    "\n",
    "        :return: A list containing all the parameters (weights and biases) of the neurons in the layer.\n",
    "        \"\"\"\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    A multi-layer perceptron (MLP) neural network, consisting of multiple layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nin: int, nouts: List[int]):\n",
    "        \"\"\"\n",
    "        Initialize an MLP with a specified number of input connections and a list of output connections per layer.\n",
    "\n",
    "        :param nin: Number of input connections to the MLP.\n",
    "        :param nouts: List specifying the number of output connections for each layer.\n",
    "        \"\"\"\n",
    "        sz = [nin] + nouts\n",
    "        self.layers: List[Layer] = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x: List[Value]) -> Union[Value, List[Value]]:\n",
    "        \"\"\"\n",
    "        Compute the output of the MLP given an input.\n",
    "\n",
    "        :param x: List of input values.\n",
    "        :return: The output values from the MLP.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self) -> List[Value]:\n",
    "        \"\"\"\n",
    "        Get all parameters of the MLP.\n",
    "\n",
    "        :return: A list containing all the parameters (weights and biases) of the neurons in all layers of the MLP.\n",
    "        \"\"\"\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.9222548123958281)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2.0, 3.0, -1.0]\n",
    "mlp = MLP(5, [4, 4, 1])\n",
    "mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0003605320228457257\n",
      "1 0.0003601014865030883\n",
      "2 0.0003596719619233537\n",
      "3 0.00035924344556235885\n",
      "4 0.0003588159338924078\n",
      "5 0.00035838942340222824\n",
      "6 0.000357963910596814\n",
      "7 0.0003575393919973982\n",
      "8 0.00035711586414130254\n",
      "9 0.00035669332358187434\n",
      "10 0.0003562717668883871\n",
      "11 0.0003558511906459517\n",
      "12 0.00035543159145541613\n",
      "13 0.0003550129659332925\n",
      "14 0.00035459531071165224\n",
      "15 0.0003541786224380243\n",
      "16 0.0003537628977753493\n",
      "17 0.0003533481334018411\n",
      "18 0.0003529343260109461\n",
      "19 0.00035252147231122123\n"
     ]
    }
   ],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets\n",
    "for k in range(20):\n",
    "  \n",
    "  # forward pass\n",
    "  ypred = [mlp(x) for x in xs]\n",
    "  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "  \n",
    "  # backward pass\n",
    "  for p in mlp.parameters():\n",
    "    p.grad = 0.0\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  for p in mlp.parameters():\n",
    "    p.data += -0.1 * p.grad\n",
    "  \n",
    "  print(k, loss.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9922222339263994),\n",
       " Value(data=-0.9921710170481529),\n",
       " Value(data=-0.9896168639431333),\n",
       " Value(data=0.9889128299922906)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
